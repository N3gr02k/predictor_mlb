{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac820f0a-08c7-4097-b3c5-9aa8c4bb870a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3522726585.py, line 99)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 99\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(\"Este es el modelo que deberías usar en tu aplicación Flask.\")S\u001b[39m\n                                                                        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Añadimos la carpeta principal al path para encontrar nuestros módulos\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "# Importamos TODAS nuestras funciones de ingeniería de características\n",
    "from src.feature_engineering import add_pythagorean_expectation, EloRatingSystem, add_elo_ratings, add_rolling_win_percentage\n",
    "\n",
    "print(\"--- Fase 4: Optimización de Hiperparámetros para XGBoost ---\")\n",
    "\n",
    "# 1. Cargar el dataset enriquecido\n",
    "csv_path = os.path.join('..', 'data', 'historical_games_rich.csv')\n",
    "df = pd.read_csv(csv_path, parse_dates=['game_date'])\n",
    "print(f\"Dataset enriquecido cargado con {df.shape} filas.\")\n",
    "\n",
    "# 2. Aplicar TODA la ingeniería de características\n",
    "df_v5 = add_pythagorean_expectation(df)\n",
    "df_v5 = add_rolling_win_percentage(df_v5)\n",
    "\n",
    "# 3. Entrenar el sistema Elo\n",
    "elo_sys = EloRatingSystem()\n",
    "df_v5['winner'] = df_v5.apply(lambda row: row['h_team_name'] if row['target'] == 1 else row['v_team_name'], axis=1)\n",
    "df_v5['loser'] = df_v5.apply(lambda row: row['v_team_name'] if row['target'] == 1 else row['h_team_name'], axis=1)\n",
    "for index, row in df_v5.sort_values('game_date').iterrows():\n",
    "    elo_sys.update_ratings(row['winner'], row['loser'])\n",
    "df_v5 = add_elo_ratings(df_v5, elo_sys)\n",
    "\n",
    "# 4. Preparar los datos\n",
    "y = df_v5['target']\n",
    "features = ['h_team_wins_season', 'h_team_losses_season', 'v_team_wins_season', 'v_team_losses_season', \n",
    "            'pythag_diff', 'elo_diff', 'win_pct_roll_diff']\n",
    "X = df_v5[features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. Optimización de Hiperparámetros con RandomizedSearchCV\n",
    "print(\"\\nIniciando la búsqueda de los mejores hiperparámetros... (Esto puede tardar unos minutos)\")\n",
    "\n",
    "# Definimos el \"espacio de búsqueda\": los ajustes que queremos probar\n",
    "param_grid = {\n",
    "    # =================================================================\n",
    "    # === LA CORRECCIÓN DEFINITIVA Y VERIFICADA ESTÁ AQUÍ ===\n",
    "    # Le damos una LISTA de valores (iterable) para que el optimizador pruebe.\n",
    "    'n_estimators': [50,100],\n",
    "    # =================================================================\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [1, 2, 3, 4, 5],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "# Creamos el modelo base\n",
    "xgb_base = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss')\n",
    "\n",
    "# Configuramos la búsqueda aleatoria\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ¡Comienza la búsqueda!\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n¡Búsqueda completada!\")\n",
    "print(f\"Los mejores parámetros encontrados son: {random_search.best_params_}\")\n",
    "\n",
    "# 6. Evaluar el modelo OPTIMIZADO\n",
    "best_model = random_search.best_estimator_\n",
    "predictions_v5 = best_model.predict(X_test)\n",
    "accuracy_v5 = accuracy_score(y_test, predictions_v5)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"  PRECISIÓN ANTERIOR (XGBoost de fábrica): 0.6411\")\n",
    "print(f\"  PRECISIÓN OPTIMIZADA (XGBoost ajustado): {accuracy_v5:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "improvement_v5 = accuracy_v5 - 0.6411\n",
    "print(f\"\\n¡Mejora por ajuste de hiperparámetros: {improvement_v5:+.2%}!\")\n",
    "total_improvement = accuracy_v5 - 0.5585\n",
    "print(f\"¡Mejora total sobre la línea base: {total_improvement:+.2%}!\")\n",
    "\n",
    "# 7. Guardar nuestro modelo campeón\n",
    "assets_dir = os.path.join('..', 'src', 'assets')\n",
    "model_path_v5 = os.path.join(assets_dir, 'mlb_model_final_tuned.joblib')\n",
    "joblib.dump(best_model, model_path_v5)\n",
    "print(f\"\\n¡Modelo final optimizado guardado en '{model_path_v5}'!\")\n",
    "print(\"Este es el modelo que deberías usar en tu aplicación Flask.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2713d6e-2827-4790-9566-3af88dc12b19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
